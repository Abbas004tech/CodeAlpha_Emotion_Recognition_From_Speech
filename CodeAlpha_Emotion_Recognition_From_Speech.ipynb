{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "977491ef-04c4-4c3f-b59d-851a22ea4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b37e9e-f031-47b3-abab-2a19173bf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to dataset (update this if needed)\n",
    "DATA_PATH = \"/Users/macbookpro/Desktop/Audio_Song_Actors_01-24\"\n",
    "\n",
    "# Map emotion codes to labels (RAVDESS format)\n",
    "emotion_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6cedbf-3841-4d13-9068-9b3426b9c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfcc_scaled = np.mean(mfcc.T, axis=0)\n",
    "        return mfcc_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file_path}\\n {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39738671-ac8a-4d79-b83d-df61990a9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 26/26 [01:16<00:00,  2.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-523.922180</td>\n",
       "      <td>36.252666</td>\n",
       "      <td>-19.905519</td>\n",
       "      <td>12.971987</td>\n",
       "      <td>-9.616239</td>\n",
       "      <td>-15.922702</td>\n",
       "      <td>-15.657978</td>\n",
       "      <td>-8.893446</td>\n",
       "      <td>-14.755669</td>\n",
       "      <td>6.043025</td>\n",
       "      <td>...</td>\n",
       "      <td>2.381103</td>\n",
       "      <td>-6.505177</td>\n",
       "      <td>-6.485410</td>\n",
       "      <td>-2.818655</td>\n",
       "      <td>1.587407</td>\n",
       "      <td>0.349844</td>\n",
       "      <td>1.351712</td>\n",
       "      <td>6.588576</td>\n",
       "      <td>7.494193</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-587.782104</td>\n",
       "      <td>43.909641</td>\n",
       "      <td>-17.656189</td>\n",
       "      <td>13.169994</td>\n",
       "      <td>-7.121557</td>\n",
       "      <td>-13.213776</td>\n",
       "      <td>-12.981407</td>\n",
       "      <td>-11.661613</td>\n",
       "      <td>-12.594746</td>\n",
       "      <td>6.062702</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169533</td>\n",
       "      <td>-4.859681</td>\n",
       "      <td>-6.721389</td>\n",
       "      <td>-4.410873</td>\n",
       "      <td>1.020319</td>\n",
       "      <td>0.567670</td>\n",
       "      <td>0.182629</td>\n",
       "      <td>5.530495</td>\n",
       "      <td>8.593582</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-564.099976</td>\n",
       "      <td>48.837444</td>\n",
       "      <td>-21.918192</td>\n",
       "      <td>7.789908</td>\n",
       "      <td>-10.597126</td>\n",
       "      <td>-16.043745</td>\n",
       "      <td>-17.649284</td>\n",
       "      <td>-11.985186</td>\n",
       "      <td>-10.888350</td>\n",
       "      <td>3.368910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.934443</td>\n",
       "      <td>-6.871836</td>\n",
       "      <td>-8.179089</td>\n",
       "      <td>-4.061671</td>\n",
       "      <td>0.859207</td>\n",
       "      <td>0.858561</td>\n",
       "      <td>0.053792</td>\n",
       "      <td>8.430861</td>\n",
       "      <td>9.631927</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-583.713745</td>\n",
       "      <td>41.609371</td>\n",
       "      <td>-17.050117</td>\n",
       "      <td>9.653690</td>\n",
       "      <td>-8.419250</td>\n",
       "      <td>-13.660363</td>\n",
       "      <td>-19.128326</td>\n",
       "      <td>-11.646488</td>\n",
       "      <td>-10.947925</td>\n",
       "      <td>4.704983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.834656</td>\n",
       "      <td>-7.705764</td>\n",
       "      <td>-7.545528</td>\n",
       "      <td>-3.399522</td>\n",
       "      <td>2.211384</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>2.038282</td>\n",
       "      <td>7.278339</td>\n",
       "      <td>8.831779</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-619.617920</td>\n",
       "      <td>36.146912</td>\n",
       "      <td>-9.827855</td>\n",
       "      <td>9.078827</td>\n",
       "      <td>-10.291913</td>\n",
       "      <td>-10.712646</td>\n",
       "      <td>-16.410923</td>\n",
       "      <td>-7.202985</td>\n",
       "      <td>-11.408434</td>\n",
       "      <td>0.565057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205038</td>\n",
       "      <td>-3.876109</td>\n",
       "      <td>-3.776702</td>\n",
       "      <td>-4.453256</td>\n",
       "      <td>1.194393</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>0.994291</td>\n",
       "      <td>1.842649</td>\n",
       "      <td>8.704984</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0 -523.922180  36.252666 -19.905519  12.971987  -9.616239 -15.922702   \n",
       "1 -587.782104  43.909641 -17.656189  13.169994  -7.121557 -13.213776   \n",
       "2 -564.099976  48.837444 -21.918192   7.789908 -10.597126 -16.043745   \n",
       "3 -583.713745  41.609371 -17.050117   9.653690  -8.419250 -13.660363   \n",
       "4 -619.617920  36.146912  -9.827855   9.078827 -10.291913 -10.712646   \n",
       "\n",
       "           6          7          8         9  ...        31        32  \\\n",
       "0 -15.657978  -8.893446 -14.755669  6.043025  ...  2.381103 -6.505177   \n",
       "1 -12.981407 -11.661613 -12.594746  6.062702  ...  3.169533 -4.859681   \n",
       "2 -17.649284 -11.985186 -10.888350  3.368910  ...  2.934443 -6.871836   \n",
       "3 -19.128326 -11.646488 -10.947925  4.704983  ...  1.834656 -7.705764   \n",
       "4 -16.410923  -7.202985 -11.408434  0.565057  ...  0.205038 -3.876109   \n",
       "\n",
       "         33        34        35        36        37        38        39  \\\n",
       "0 -6.485410 -2.818655  1.587407  0.349844  1.351712  6.588576  7.494193   \n",
       "1 -6.721389 -4.410873  1.020319  0.567670  0.182629  5.530495  8.593582   \n",
       "2 -8.179089 -4.061671  0.859207  0.858561  0.053792  8.430861  9.631927   \n",
       "3 -7.545528 -3.399522  2.211384  0.861499  2.038282  7.278339  8.831779   \n",
       "4 -3.776702 -4.453256  1.194393  0.420987  0.994291  1.842649  8.704984   \n",
       "\n",
       "     label  \n",
       "0    happy  \n",
       "1    happy  \n",
       "2     calm  \n",
       "3     calm  \n",
       "4  neutral  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "for folder in tqdm(os.listdir(DATA_PATH)):\n",
    "    folder_path = os.path.join(DATA_PATH, folder)\n",
    "    if not os.path.isdir(folder_path) or folder.startswith('.'):\n",
    "        continue  # Skip system files like .DS_Store\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            emotion_code = file.split(\"-\")[2]\n",
    "            emotion = emotion_map.get(emotion_code)\n",
    "            if emotion:\n",
    "                feature = extract_features(os.path.join(folder_path, file))\n",
    "                if feature is not None:\n",
    "                    features.append(feature)\n",
    "                    labels.append(emotion)\n",
    "\n",
    "df = pd.DataFrame(features)\n",
    "df['label'] = labels\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38613d5-6ca8-42cf-b3ec-bc57ea701394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode emotion labels to integers\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87518703-ce06-48d2-95d9-29a3ca1ebda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.1904 - loss: 33.8758 - val_accuracy: 0.1970 - val_loss: 5.6314\n",
      "Epoch 2/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1939 - loss: 9.6931 - val_accuracy: 0.2167 - val_loss: 2.9975\n",
      "Epoch 3/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1952 - loss: 5.5906 - val_accuracy: 0.1527 - val_loss: 2.1091\n",
      "Epoch 4/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1947 - loss: 3.9362 - val_accuracy: 0.2069 - val_loss: 1.9451\n",
      "Epoch 5/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1757 - loss: 3.0521 - val_accuracy: 0.1478 - val_loss: 1.7834\n",
      "Epoch 6/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1740 - loss: 2.6636 - val_accuracy: 0.2069 - val_loss: 1.7945\n",
      "Epoch 7/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1831 - loss: 2.2720 - val_accuracy: 0.2020 - val_loss: 1.7918\n",
      "Epoch 8/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1705 - loss: 2.0011 - val_accuracy: 0.2069 - val_loss: 1.7666\n",
      "Epoch 9/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1881 - loss: 2.0160 - val_accuracy: 0.1182 - val_loss: 1.8074\n",
      "Epoch 10/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1742 - loss: 1.9414 - val_accuracy: 0.2020 - val_loss: 1.7908\n",
      "Epoch 11/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1808 - loss: 1.8612 - val_accuracy: 0.1626 - val_loss: 1.7881\n",
      "Epoch 12/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1991 - loss: 1.8394 - val_accuracy: 0.1872 - val_loss: 1.7792\n",
      "Epoch 13/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1681 - loss: 1.8736 - val_accuracy: 0.1576 - val_loss: 1.7840\n",
      "Epoch 14/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1857 - loss: 1.7962 - val_accuracy: 0.1724 - val_loss: 1.7755\n",
      "Epoch 15/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2133 - loss: 1.8129 - val_accuracy: 0.1478 - val_loss: 1.7817\n",
      "Epoch 16/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2211 - loss: 1.7620 - val_accuracy: 0.1478 - val_loss: 1.7798\n",
      "Epoch 17/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1980 - loss: 1.7997 - val_accuracy: 0.1675 - val_loss: 1.7756\n",
      "Epoch 18/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1942 - loss: 1.7992 - val_accuracy: 0.2365 - val_loss: 1.7739\n",
      "Epoch 19/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2182 - loss: 1.7906 - val_accuracy: 0.1626 - val_loss: 1.7860\n",
      "Epoch 20/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2041 - loss: 1.8008 - val_accuracy: 0.1429 - val_loss: 1.7897\n",
      "Epoch 21/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2220 - loss: 1.7699 - val_accuracy: 0.1478 - val_loss: 1.7784\n",
      "Epoch 22/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2080 - loss: 1.7961 - val_accuracy: 0.2365 - val_loss: 1.7715\n",
      "Epoch 23/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1995 - loss: 1.7734 - val_accuracy: 0.2315 - val_loss: 1.7740\n",
      "Epoch 24/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2073 - loss: 1.7710 - val_accuracy: 0.1576 - val_loss: 1.7782\n",
      "Epoch 25/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2086 - loss: 1.7728 - val_accuracy: 0.2611 - val_loss: 1.7693\n",
      "Epoch 26/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2178 - loss: 1.7721 - val_accuracy: 0.2365 - val_loss: 1.7674\n",
      "Epoch 27/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2212 - loss: 1.7582 - val_accuracy: 0.1576 - val_loss: 1.7738\n",
      "Epoch 28/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1909 - loss: 1.7870 - val_accuracy: 0.1970 - val_loss: 1.7675\n",
      "Epoch 29/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1994 - loss: 1.7644 - val_accuracy: 0.1626 - val_loss: 1.7622\n",
      "Epoch 30/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2424 - loss: 1.7643 - val_accuracy: 0.2709 - val_loss: 1.7584\n",
      "Epoch 31/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1993 - loss: 1.7750 - val_accuracy: 0.2315 - val_loss: 1.7704\n",
      "Epoch 32/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2196 - loss: 1.7491 - val_accuracy: 0.2857 - val_loss: 1.7550\n",
      "Epoch 33/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2090 - loss: 1.7611 - val_accuracy: 0.2217 - val_loss: 1.7626\n",
      "Epoch 34/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1989 - loss: 1.7573 - val_accuracy: 0.1675 - val_loss: 1.7618\n",
      "Epoch 35/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2150 - loss: 1.7632 - val_accuracy: 0.1773 - val_loss: 1.7684\n",
      "Epoch 36/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2141 - loss: 1.7517 - val_accuracy: 0.1675 - val_loss: 1.7563\n",
      "Epoch 37/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2096 - loss: 1.7778 - val_accuracy: 0.1724 - val_loss: 1.7654\n",
      "Epoch 38/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2291 - loss: 1.7556 - val_accuracy: 0.2759 - val_loss: 1.7663\n",
      "Epoch 39/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2136 - loss: 1.7393 - val_accuracy: 0.2167 - val_loss: 1.7339\n",
      "Epoch 40/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2120 - loss: 1.7666 - val_accuracy: 0.1724 - val_loss: 1.7550\n",
      "Epoch 41/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2109 - loss: 1.7480 - val_accuracy: 0.1773 - val_loss: 1.7497\n",
      "Epoch 42/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2308 - loss: 1.7283 - val_accuracy: 0.1724 - val_loss: 1.7452\n",
      "Epoch 43/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2345 - loss: 1.7333 - val_accuracy: 0.2069 - val_loss: 1.7515\n",
      "Epoch 44/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2487 - loss: 1.7326 - val_accuracy: 0.2365 - val_loss: 1.7417\n",
      "Epoch 45/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2454 - loss: 1.7654 - val_accuracy: 0.2414 - val_loss: 1.7349\n",
      "Epoch 46/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2339 - loss: 1.7443 - val_accuracy: 0.1724 - val_loss: 1.7500\n",
      "Epoch 47/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2204 - loss: 1.7403 - val_accuracy: 0.1823 - val_loss: 1.7364\n",
      "Epoch 48/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2606 - loss: 1.7358 - val_accuracy: 0.2512 - val_loss: 1.7182\n",
      "Epoch 49/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2145 - loss: 1.7355 - val_accuracy: 0.1921 - val_loss: 1.7216\n",
      "Epoch 50/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2668 - loss: 1.7224 - val_accuracy: 0.2266 - val_loss: 1.7070\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define a simple model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e29e74e6-a077-4694-b051-62efd2711482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "✅ Accuracy: 0.22660098522167488\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.27      0.73      0.39        30\n",
      "        calm       0.00      0.00      0.00        44\n",
      "     fearful       0.13      0.45      0.21        29\n",
      "       happy       0.00      0.00      0.00        39\n",
      "     neutral       0.00      0.00      0.00        21\n",
      "         sad       0.50      0.28      0.35        40\n",
      "\n",
      "    accuracy                           0.23       203\n",
      "   macro avg       0.15      0.24      0.16       203\n",
      "weighted avg       0.16      0.23      0.16       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print results\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b85228-c12e-4b6e-b8a8-0c930623dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model.save(\"final_emotion_model.h5\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff9f500-3fd5-4aca-9efe-61862ecef0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "✅ Predicted Emotion: fearful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained model and label encoder\n",
    "model = load_model(\"final_emotion_model.h5\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "def predict_emotion(audio_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfcc_scaled = np.mean(mfcc.T, axis=0).reshape(1, -1)\n",
    "\n",
    "        prediction = model.predict(mfcc_scaled)\n",
    "        predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "\n",
    "        print(f\"✅ Predicted Emotion: {predicted_label[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "# 🔁 Run prediction with a real audio file path\n",
    "predict_emotion(\"/Users/macbookpro/Desktop/Audio_Song_Actors_01-24/Actor_01/03-02-01-01-01-01-01.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6110d509-f0cf-4015-9e19-114f3bba300e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "🎧 03-02-03-02-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "🎧 03-02-03-01-01-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "🎧 03-02-02-02-01-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "🎧 03-02-02-01-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "🎧 03-02-01-01-02-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "🎧 03-02-06-01-02-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "🎧 03-02-05-01-02-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "🎧 03-02-05-02-01-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "🎧 03-02-06-02-01-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "🎧 03-02-04-01-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "🎧 03-02-04-02-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "🎧 03-02-05-01-01-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "🎧 03-02-06-01-01-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "🎧 03-02-06-02-02-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "🎧 03-02-05-02-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "🎧 03-02-04-01-02-01-01.wav => 🧠 Predicted Emotion: sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "🎧 03-02-04-02-01-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "🎧 03-02-03-02-01-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "🎧 03-02-03-01-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "🎧 03-02-02-02-02-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "🎧 03-02-01-01-01-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "🎧 03-02-02-01-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "🎧 03-02-04-02-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "🎧 03-02-04-01-01-01-01.wav => 🧠 Predicted Emotion: sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "🎧 03-02-06-02-01-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "🎧 03-02-05-02-01-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "🎧 03-02-05-01-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "🎧 03-02-06-01-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "🎧 03-02-01-01-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "🎧 03-02-02-01-02-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "🎧 03-02-02-02-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "🎧 03-02-03-01-01-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "🎧 03-02-03-02-02-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "🎧 03-02-02-01-01-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "🎧 03-02-01-01-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "🎧 03-02-02-02-02-01-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "🎧 03-02-03-01-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "🎧 03-02-03-02-01-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "🎧 03-02-04-02-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "🎧 03-02-04-01-02-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "🎧 03-02-05-02-02-01-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "🎧 03-02-06-02-02-02-01.wav => 🧠 Predicted Emotion: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "🎧 03-02-06-01-01-02-01.wav => 🧠 Predicted Emotion: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "🎧 03-02-05-01-01-01-01.wav => 🧠 Predicted Emotion: angry\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = load_model(\"final_emotion_model.h5\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Function to predict emotion\n",
    "def predict_emotion(audio_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfcc_scaled = np.mean(mfcc.T, axis=0).reshape(1, -1)\n",
    "        prediction = model.predict(mfcc_scaled)\n",
    "        predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "        return predicted_label[0]\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error for {audio_path}: {str(e)}\"\n",
    "\n",
    "# Folder containing audio files\n",
    "audio_folder = \"/Users/macbookpro/Desktop/Audio_Song_Actors_01-24/Actor_01\"\n",
    "\n",
    "# Predict emotions for all .wav files\n",
    "for file in os.listdir(audio_folder):\n",
    "    if file.endswith(\".wav\"):\n",
    "        full_path = os.path.join(audio_folder, file)\n",
    "        emotion = predict_emotion(full_path)\n",
    "        print(f\"🎧 {file} => 🧠 Predicted Emotion: {emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1f894-ceec-4d2b-8b2f-221402766781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
